{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Character Level Multi Layer Perceptron Language Model**\n",
    "This is inspired by [A Neural Probabilistic Language Model](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf) paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '<',\n",
       " 27: '>'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create lookup table for converting characters to indices\n",
    "chars = sorted(list(set(''.join(words)))) # all unique characters in the dataset\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)} # string to index\n",
    "\n",
    "# manually enumerate start and end token since they are not visible in the dataset\n",
    "start_token = '<'\n",
    "end_token = '>'\n",
    "stoi[start_token] = 0\n",
    "stoi[end_token] = len(stoi)\n",
    "\n",
    "# total number of unique characters plus start and end token\n",
    "chars_count = len(stoi)\n",
    "\n",
    "# index to string\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "itos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset\n",
    "Based on given list of words creates input tensor with sequence of characters  with length equal to 'context_length' and target tensor with next character in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, context_length=3):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [stoi[start_token]] * context_length # context window padded with start token\n",
    "        for ch in w + end_token:\n",
    "            ix = stoi[ch]\n",
    "            X.append(context) # for given context ...\n",
    "            Y.append(ix) # ... the next character is the target\n",
    "            context = context[1:] + [ix] # crop and append - sliding window\n",
    "    \n",
    "    return torch.tensor(X), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = torch.Size([5, 3]), X.dtype = torch.int64\n",
      "Y.shape = torch.Size([5]), Y.dtype = torch.int64\n",
      "For the first word in the dataset: <emma>\n",
      "X[0] = [0, 0, 0] = <<< ---and target char is--> Y[0] = 5 = e\n",
      "X[1] = [0, 0, 5] = <<e ---and target char is--> Y[1] = 13 = m\n",
      "X[2] = [0, 5, 13] = <em ---and target char is--> Y[2] = 13 = m\n",
      "X[3] = [5, 13, 13] = emm ---and target char is--> Y[3] = 1 = a\n",
      "X[4] = [13, 13, 1] = mma ---and target char is--> Y[4] = 27 = >\n"
     ]
    }
   ],
   "source": [
    "# X (input) and Y (output/target/label) tensors\n",
    "X, Y = build_dataset(words[:1])\n",
    "print(f'X.shape = {X.shape}, X.dtype = {X.dtype}')\n",
    "print(f'Y.shape = {Y.shape}, Y.dtype = {Y.dtype}')\n",
    "\n",
    "print(f'For the first word in the dataset: {start_token + words[0] + end_token}')\n",
    "for i in range(len(X)):\n",
    "    print(f\"X[{i}] = {X[i].tolist()} = {''.join([itos[j] for j in X[i].tolist()])}\"\n",
    "          f\" ---and target char is--> Y[{i}] = {Y[i]} = {itos[Y[i].item()]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embedding lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding using index C[15]=tensor([-0.9548, -0.5612])\n",
      "Embedding using one-hot encoding and matrix multiplication=tensor([[-0.9548, -0.5612]])\n",
      "Embedding for sequence of three characters C[torch.tensor([15, 20, 5])]=\n",
      "tensor([[-0.9548, -0.5612],\n",
      "        [-0.7950, -0.3042],\n",
      "        [ 2.8488,  0.9872]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix of embeddings\n",
    "C = torch.randn((chars_count, 2)) # 2-dimensional embeddings\n",
    "\n",
    "# Example of embedding single character with index 15\n",
    "# since our matrix of embeddings is the same size as the number of characters\n",
    "# we can simply use the index of the character to get its embedding\n",
    "example_embedding = C[15]\n",
    "print(f'Embedding using index C[15]={example_embedding}')\n",
    "\n",
    "# Alternative approach would be to one-hot encode the character and then multiply it by the embedding matrix\n",
    "# this will give same result because encoded vector will have only one non-zero value equal to 1\n",
    "# and this will simply act as a mask for the embedding matrix\n",
    "example_embedding = F.one_hot(torch.tensor([15]), num_classes=chars_count).float() @ C\n",
    "print(f'Embedding using one-hot encoding and matrix multiplication={example_embedding}')\n",
    "\n",
    "# For rest of of notebook I will use index based approach because it is more efficient\n",
    "# also thanks to python semantics we can easly retrieve embedding for whole sequence of characters\n",
    "# by indexing with list or tensor of integers\n",
    "example_embedding = C[torch.tensor([15, 20, 5])]\n",
    "print(f'Embedding for sequence of three characters C[torch.tensor([15, 20, 5])]=\\n{example_embedding}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of C[X].shape=torch.Size([5, 3, 2])\n",
      "And C[X] =\n",
      "tensor([[[-1.1085, -1.7753],\n",
      "         [-1.1085, -1.7753],\n",
      "         [-1.1085, -1.7753]],\n",
      "\n",
      "        [[-1.1085, -1.7753],\n",
      "         [-1.1085, -1.7753],\n",
      "         [ 2.8488,  0.9872]],\n",
      "\n",
      "        [[-1.1085, -1.7753],\n",
      "         [ 2.8488,  0.9872],\n",
      "         [ 0.3626, -0.8098]],\n",
      "\n",
      "        [[ 2.8488,  0.9872],\n",
      "         [ 0.3626, -0.8098],\n",
      "         [ 0.3626, -0.8098]],\n",
      "\n",
      "        [[ 0.3626, -0.8098],\n",
      "         [ 0.3626, -0.8098],\n",
      "         [ 1.0749, -1.9479]]])\n",
      "We can also access individual ebeddings for given sequence, for example C[X][0] =\n",
      "tensor([[-1.1085, -1.7753],\n",
      "        [-1.1085, -1.7753],\n",
      "        [-1.1085, -1.7753]])\n",
      "Or even embedding for individual character in sequence, for example C[X][0][0] =\n",
      "tensor([-1.1085, -1.7753])\n"
     ]
    }
   ],
   "source": [
    "# What is even more mind blowing is that we can index using multidimensional tensor!\n",
    "# in this exaple where X is 5x3 tensor, we will get 5x3x2 tensor with embeddings for each character in each sequence in third dimension\n",
    "print(f'Shape of C[X].shape={C[X].shape}')\n",
    "print(f'And C[X] =\\n{C[X]}')\n",
    "print(f'We can also access individual ebeddings for given sequence, for example C[X][0] =\\n{C[X][0]}')\n",
    "print(f'Or even embedding for individual character in sequence, for example C[X][0][0] =\\n{C[X][0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings for imput sequences\n",
    "X_embedded = C[X]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP input and hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer_size=6\n",
      "hidden_layer_size=100\n",
      "W1.shape=torch.Size([6, 100])\n",
      "b1.shape=torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Number of inputs for first layer\n",
    "# context length * number of embeddings for each character\n",
    "# in our case 3 * 2 = 6 which is the same as shape[1] * shape[2] of X_embedded\n",
    "# and we will pass embeddings for each character in the sequence as input to the network\n",
    "input_layer_size = X_embedded.shape[1] * X_embedded.shape[2]\n",
    "print(f'input_layer_size={input_layer_size}')\n",
    "\n",
    "# number of neurons in hidden layer\n",
    "hidden_layer_size = 100\n",
    "print(f'hidden_layer_size={hidden_layer_size}')\n",
    "\n",
    "# W1 represents neural network weights between input and hidden layer\n",
    "W1 = torch.randn((input_layer_size, hidden_layer_size))\n",
    "print(f'W1.shape={W1.shape}')\n",
    "\n",
    "# b1 represents bias for hidden layer\n",
    "b1 = torch.randn(hidden_layer_size)\n",
    "print(f'b1.shape={b1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_embedded[:, 0, :]=\n",
      "tensor([[-1.1085, -1.7753],\n",
      "        [-1.1085, -1.7753],\n",
      "        [-1.1085, -1.7753],\n",
      "        [ 2.8488,  0.9872],\n",
      "        [ 0.3626, -0.8098]])\n",
      "\n",
      "torch.concat + tensor list=\n",
      "tensor([[-1.1085, -1.7753, -1.1085, -1.7753, -1.1085, -1.7753],\n",
      "        [-1.1085, -1.7753, -1.1085, -1.7753,  2.8488,  0.9872],\n",
      "        [-1.1085, -1.7753,  2.8488,  0.9872,  0.3626, -0.8098],\n",
      "        [ 2.8488,  0.9872,  0.3626, -0.8098,  0.3626, -0.8098],\n",
      "        [ 0.3626, -0.8098,  0.3626, -0.8098,  1.0749, -1.9479]])\n",
      "\n",
      "torch.concat + torch.unbind=\n",
      "tensor([[-1.1085, -1.7753, -1.1085, -1.7753, -1.1085, -1.7753],\n",
      "        [-1.1085, -1.7753, -1.1085, -1.7753,  2.8488,  0.9872],\n",
      "        [-1.1085, -1.7753,  2.8488,  0.9872,  0.3626, -0.8098],\n",
      "        [ 2.8488,  0.9872,  0.3626, -0.8098,  0.3626, -0.8098],\n",
      "        [ 0.3626, -0.8098,  0.3626, -0.8098,  1.0749, -1.9479]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In order to perform matrix multiplication between input and weights we need to \n",
    "# transform input tensor which is 5x3x2 into 5x6 to fit into neural network\n",
    "\n",
    "# This is how to access all embeddings for first character in each sequence\n",
    "print(f'X_embedded[:, 0, :]=\\n{X_embedded[:, 0, :]}\\n')\n",
    "\n",
    "# Knowing above we can concatenate all embeddings for each character in each sequence\n",
    "print(f'torch.concat + tensor list=\\n{torch.concat([X_embedded[:, i, :] for i in range(X_embedded.shape[1])], dim=1)}\\n')\n",
    "\n",
    "# We can also improve it by using torch.unbind which will return list of tensors and yield same result as for loop\n",
    "print(f'torch.concat + torch.unbind=\\n{torch.concat(torch.unbind(X_embedded, dim=1), dim=1)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape=torch.Size([16]), a=tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "\n",
      "a.view(2, 8)=\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14, 15]])\n",
      "\n",
      "a.view(4, 4)=\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "\n",
      "a.view(2, 2, 4)=\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7]],\n",
      "\n",
      "        [[ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# But it turns out there is another great function in pytorch called torch.view\n",
    "# Lets have some fun with it\n",
    "\n",
    "a = torch.arange(16) # 1D tensor with 16 elements\n",
    "print(f'a.shape={a.shape}, a={a}\\n')\n",
    "print(f'a.view(2, 8)=\\n{a.view(2, 8)}\\n')\n",
    "print(f'a.view(4, 4)=\\n{a.view(4, 4)}\\n')\n",
    "print(f'a.view(2, 2, 4)=\\n{a.view(2, 2, 4)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_embedded_flat.shape=torch.Size([5, 6])\n",
      "\n",
      "X_embedded_flat=\n",
      "tensor([[-1.1085, -1.7753, -1.1085, -1.7753, -1.1085, -1.7753],\n",
      "        [-1.1085, -1.7753, -1.1085, -1.7753,  2.8488,  0.9872],\n",
      "        [-1.1085, -1.7753,  2.8488,  0.9872,  0.3626, -0.8098],\n",
      "        [ 2.8488,  0.9872,  0.3626, -0.8098,  0.3626, -0.8098],\n",
      "        [ 0.3626, -0.8098,  0.3626, -0.8098,  1.0749, -1.9479]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Knowing above we can use torch.view to transform our 5x3x2 tensor into 5x6\n",
    "# Basically we just keep first dimension and merge all other dimensions into one\n",
    "# Also it looks like 6 is the only possible value for second dimension because 3*2=6\n",
    "# Knowing that we can use -1 for second dimension and pytorch will figure out the rest\n",
    "X_embedded_flat = X_embedded.view(-1, 6)\n",
    "print(f'X_embedded_flat.shape={X_embedded_flat.shape}\\n')\n",
    "print(f'X_embedded_flat=\\n{X_embedded_flat}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First layer multiplication to get outputs from hidden layer\n",
    "Our current desing of network is: 6 inputs which represents 2 dimensional embeddings for 3 character long sequence that go into 100 neurons in hidden layer and what we get is 100 outputs for each input sequence.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h.shape=torch.Size([5, 100])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h = torch.tanh(X_embedded_flat @ W1 + b1) \n",
    "# + b1 is broadcasted to match shape of X_embedded_flat @ W1\n",
    "# 5, 100\n",
    "# 1, 100 - broadcasting will align on the right, create fake dimension on the left\n",
    "# and will be copy b1 values 5 times to match shape of (X_embedded_flat @ W1) and perform elementwise addition\n",
    "# and will result of adding 5x100 matrix to 5x100 matrix with copied values from b1\n",
    "print(f'h.shape={h.shape}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output layer\n",
    "Takes 100 outputs from hidden layer and produces output that represent one_hot_encoding for our characters set for each input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((hidden_layer_size, chars_count))\n",
    "b2 = torch.randn(chars_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forwad pass for output layer\n",
    "logits = h @ W2 + b2\n",
    "\n",
    "# calculate output probabilities (the old way, manualy calculating softmax)\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "# but there is faster way to calculate probabilities - use torch.nn.functional.softmax\n",
    "# and this is equivalent to above calculation\n",
    "probs = F.softmax(logits, dim=1)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2586e-05, 4.2973e-05, 1.2516e-06, 7.0817e-02, 4.9474e-12, 2.1699e-05,\n",
       "        6.3958e-07, 3.8573e-05, 9.2183e-01, 1.9690e-05, 7.4372e-08, 7.1063e-03,\n",
       "        1.3407e-07, 1.9112e-10, 4.1595e-12, 9.5417e-06, 8.4435e-05, 7.4271e-13,\n",
       "        3.3624e-09, 2.6714e-11, 1.2490e-07, 1.2856e-06, 6.5364e-08, 1.5892e-11,\n",
       "        3.8218e-07, 1.6293e-06, 6.8505e-09, 4.5347e-09])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And what we see here is output character probabilities for second input sequence\n",
    "probs[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before training = 14.321484565734863\n"
     ]
    }
   ],
   "source": [
    "# iterator over input sequences\n",
    "it = torch.arange(X_embedded.shape[0])\n",
    "\n",
    "# extract probabilities for target characters\n",
    "target_probs = probs[it, Y]\n",
    "\n",
    "# calculate loss as average negative log likelihood\n",
    "loss = -torch.log(target_probs).mean()\n",
    "\n",
    "print(f'Loss before training = {loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
